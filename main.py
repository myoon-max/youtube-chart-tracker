import os
import re
import time
import json
import requests
from datetime import datetime
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By

# ================= ì„¤ì • =================
YOUTUBE_API_KEY = "AIzaSyDFFZNYygA85qp5p99qUG2Mh8Kl5qoLip4"

TARGET_URLS = {
    # 1, 2, 3ë²ˆ ì ˆëŒ€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ (ê¸°ì¡´ ìœ ì§€)
    "KR_Daily_Trending": "https://charts.youtube.com/charts/TrendingVideos/kr/RightNow",
    "US_Daily_Trending": "https://charts.youtube.com/charts/TrendingVideos/us/RightNow",
    "KR_Daily_Top_MV": "https://charts.youtube.com/charts/TopVideos/kr/daily",
    "US_Daily_Top_MV": "https://charts.youtube.com/charts/TopVideos/us/daily",
    "KR_Weekly_Top_MV": "https://charts.youtube.com/charts/TopVideos/kr/weekly",
    "US_Weekly_Top_MV": "https://charts.youtube.com/charts/TopVideos/us/weekly",
    "KR_Weekly_Top_Songs": "https://charts.youtube.com/charts/TopSongs/kr/weekly",
    "US_Weekly_Top_Songs": "https://charts.youtube.com/charts/TopSongs/us/weekly",
    
    # 4. Shorts (HTML í…ìŠ¤íŠ¸ ë‹¨ìˆœ ë¬´ì‹ íŒŒì‹±ìœ¼ë¡œ ë³€ê²½)
    "KR_Daily_Top_Shorts": "https://charts.youtube.com/charts/TopShortsSongs/kr/daily",
    "US_Daily_Top_Shorts": "https://charts.youtube.com/charts/TopShortsSongs/us/daily"
}

# ================= ìœ í‹¸ë¦¬í‹° =================
def parse_count_strict(text):
    if not text: return 0
    t = str(text).lower().strip().replace(',', '')
    multiplier = 1
    if 'k' in t: multiplier = 1_000
    elif 'm' in t: multiplier = 1_000_000
    elif 'b' in t: multiplier = 1_000_000_000
    clean = re.sub(r'[^\d.]', '', t)
    if not clean: return 0
    try:
        val = float(clean)
        return int(val * multiplier)
    except: return 0

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--lang=en-US") 
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

# ================= Shorts ë”¥ë‹¤ì´ë¸Œ (82K ê¸ê¸°) =================
def get_shorts_creation_count(driver, video_id):
    if not video_id: return 0
    url = f"https://www.youtube.com/source/{video_id}/shorts"
    try:
        driver.get(url)
        time.sleep(1)
        body_text = driver.find_element(By.TAG_NAME, "body").text
        # "82K Shorts" íŒ¨í„´ ì°¾ê¸°
        match = re.search(r'([\d,.]+[KMB]?)\s*Shorts', body_text, re.IGNORECASE)
        if match:
            return parse_count_strict(match.group(1))
        return 0
    except: return 0

# ================= API ì¡°íšŒ (Trending ì „ìš©) =================
def get_views_from_api(video_ids):
    if not video_ids: return {}
    url = "https://www.googleapis.com/youtube/v3/videos"
    stats_map = {}
    for i in range(0, len(video_ids), 50):
        chunk = video_ids[i:i+50]
        params = {"part": "statistics", "id": ",".join(chunk), "key": YOUTUBE_API_KEY}
        try:
            res = requests.get(url, params=params).json()
            if "items" in res:
                for item in res["items"]:
                    vid = item["id"]
                    view_count = int(item["statistics"].get("viewCount", 0))
                    stats_map[vid] = view_count
        except: pass
    return stats_map

# ================= ë©”ì¸ ìŠ¤í¬ë˜í¼ =================
def scrape_chart(chart_name, url, driver):
    print(f"ğŸš€ Scraping {chart_name}...")
    driver.get(url)
    time.sleep(5) # ì´ˆê¸° ë¡œë”©
    
    data_list = []
    today = datetime.now().strftime("%Y-%m-%d")
    
    is_trending = "Trending" in chart_name
    is_shorts = "Shorts" in chart_name
    is_daily_mv = "Daily_Top_MV" in chart_name
    is_weekly = "Weekly" in chart_name
    
    # ---------------------------------------------------------
    # CASE 1: Shorts (HTML í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë°©ì‹ - ë¬´ì¡°ê±´ ì„±ê³µí•¨)
    # ---------------------------------------------------------
    if is_shorts:
        print("  â†³ Shorts Mode: Parsing HTML text directly for IDs...")
        
        # ìŠ¤í¬ë¡¤ ë‚´ë ¤ì„œ ë°ì´í„° ë¡œë”©
        last_height = driver.execute_script("return document.body.scrollHeight")
        for _ in range(30):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.5)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height: break
            last_height = new_height
        time.sleep(2)

        # [í•µì‹¬ ìˆ˜ì •] Selenium Element ì•ˆ ì”€. ì „ì²´ ì†ŒìŠ¤ë¥¼ BS4ë¡œ ë– ì„œ í…ìŠ¤íŠ¸ ìì²´ë¥¼ ë¶„ì„í•¨.
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        rows = soup.find_all('ytmc-entry-row')

        for idx, row in enumerate(rows):
            try:
                title = row.find('div', class_='title').get_text(strip=True)
                artist_tag = row.find('span', class_='artistName') or row.find('div', class_='subtitle')
                artist = artist_tag.get_text(strip=True) if artist_tag else ""
                
                # ë‹˜ê»˜ì„œ ë³´ì‹  ê·¸ JSON í…ìŠ¤íŠ¸ê°€ HTML ì•ˆì— ìˆìœ¼ë¯€ë¡œ, Row ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë°”ê¿”ì„œ ì°¾ìŠµë‹ˆë‹¤.
                row_html = str(row)
                vid = ""
                # íŒ¨í„´: watch?v=ID (ì´ê±´ ì†ŒìŠ¤ì½”ë“œì— ë¬´ì¡°ê±´ ìˆìŒ)
                match = re.search(r'watch\?v=([a-zA-Z0-9_-]{11})', row_html)
                if match:
                    vid = match.group(1)
                
                # IDë¥¼ ì°¾ì•˜ìœ¼ë©´ ë°”ë¡œ ë”¥ë‹¤ì´ë¸Œ ì‹¤í–‰
                shorts_count = 0
                if vid:
                    shorts_count = get_shorts_creation_count(driver, vid)
                
                data_list.append({
                    "Date": today, "Chart": chart_name, "Rank": idx+1,
                    "Title": title, "Artist": artist, "Video_ID": vid, "Views": shorts_count
                })
            except: continue

    # ---------------------------------------------------------
    # CASE 2: MV / Songs / Trending (ê¸°ì¡´ ì½”ë“œ 100% ìœ ì§€)
    # ---------------------------------------------------------
    else:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(3)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        rows = soup.find_all('ytmc-entry-row')
        
        for idx, row in enumerate(rows):
            try:
                title = row.find('div', class_='title').get_text(strip=True)
                artist_tag = row.find('span', class_='artistName') or row.find('div', class_='subtitle')
                artist = artist_tag.get_text(strip=True) if artist_tag else ""
                
                vid = ""
                anchor = row.find('a')
                if anchor and 'href' in anchor.attrs:
                    m = re.search(r"v=([A-Za-z0-9_-]{11})", anchor['href'])
                    if m: vid = m.group(1)
                
                if not vid:
                    img = row.find('img')
                    if img and 'src' in img.attrs:
                        m = re.search(r'/vi(?:_webp)?/([a-zA-Z0-9_-]{11})', img['src'])
                        if m: vid
