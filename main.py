import os
import json
import requests
import pandas as pd
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time
import re

# ================= ì„¤ì • =================
YOUTUBE_API_KEY = "AIzaSyDFFZNYygA85qp5p99qUG2Mh8Kl5qoLip4"

TARGET_URLS = {
    # 1. Trending (API ìœ ì§€ - ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
    "KR_Daily_Trending": "https://charts.youtube.com/charts/TrendingVideos/kr/RightNow",
    "US_Daily_Trending": "https://charts.youtube.com/charts/TrendingVideos/us/RightNow",
    
    # 2. Daily MV (ìŠ¤í¬ë¦°ìƒ· ê¸°ë°˜ Hidden íƒœê·¸ ì •ë°€ íƒ€ê²©)
    "KR_Daily_Top_MV": "https://charts.youtube.com/charts/TopVideos/kr/daily",
    "US_Daily_Top_MV": "https://charts.youtube.com/charts/TopVideos/us/daily",

    # 3. Weekly (ê¸°ì¡´ ì½”ë“œ ìœ ì§€ - ì˜ ì‘ë™í•¨)
    "KR_Weekly_Top_MV": "https://charts.youtube.com/charts/TopVideos/kr/weekly",
    "US_Weekly_Top_MV": "https://charts.youtube.com/charts/TopVideos/us/weekly",
    "KR_Weekly_Top_Songs": "https://charts.youtube.com/charts/TopSongs/kr/weekly",
    "US_Weekly_Top_Songs": "https://charts.youtube.com/charts/TopSongs/us/weekly",
    
    # 4. Shorts (ID ì¶”ì¶œ ë°©ì‹: Method 3 Anchor íƒœê·¸ ì ìš©)
    "KR_Daily_Top_Shorts": "https://charts.youtube.com/charts/TopShortsSongs/kr/daily",
    "US_Daily_Top_Shorts": "https://charts.youtube.com/charts/TopShortsSongs/us/daily"
}

# ================= ìˆ«ì ë³€í™˜ê¸° =================
def parse_count_strict(text):
    if not text: return 0
    t = str(text).lower().strip()
    
    multiplier = 1
    if 'k' in t: multiplier = 1_000
    elif 'm' in t: multiplier = 1_000_000
    elif 'b' in t: multiplier = 1_000_000_000
    
    clean = re.sub(r'[^\d.]', '', t)
    if not clean: return 0
    
    try:
        val = float(clean)
        return int(val * multiplier)
    except: return 0

# ================= API ì¡°íšŒ (Trending ì „ìš©) =================
def get_views_from_api(video_ids):
    if not video_ids: return {}
    url = "https://www.googleapis.com/youtube/v3/videos"
    stats_map = {}
    for i in range(0, len(video_ids), 50):
        chunk = video_ids[i:i+50]
        params = {"part": "statistics", "id": ",".join(chunk), "key": YOUTUBE_API_KEY}
        try:
            res = requests.get(url, params=params).json()
            if "items" in res:
                for item in res["items"]:
                    vid = item["id"]
                    view_count = int(item["statistics"].get("viewCount", 0))
                    stats_map[vid] = view_count
        except: pass
    return stats_map

# ================= ì‡¼ì¸  ê°œìˆ˜ ë”¥ë‹¤ì´ë¸Œ =================
def get_shorts_count_deep(driver, video_id):
    if not video_id: return 0
    # Source ID ê¸°ë°˜ì´ ì•„ë‹ˆë¼ Video ID ê¸°ë°˜ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ íƒœìš°ëŠ”ê²Œ ë” ì•ˆì „
    url = f"https://www.youtube.com/source/{video_id}/shorts"
    try:
        driver.get(url)
        time.sleep(1.5) 
        body_text = driver.find_element(By.TAG_NAME, "body").text
        # "82K shorts" ë˜ëŠ” "1.2M videos" íŒ¨í„´
        match = re.search(r'([\d,.]+[KMB]?)\s*(shorts|videos)', body_text, re.IGNORECASE)
        if match:
            return parse_count_strict(match.group(1))
        return 0
    except: return 0

# ================= ë“œë¼ì´ë²„ ì„¤ì • =================
def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--lang=en-US") 
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

# ================= ë©”ì¸ ìŠ¤í¬ë˜í•‘ =================
def scrape_chart(driver, chart_name, url):
    print(f"ğŸš€ Scraping {chart_name}...")
    driver.get(url)
    
    time.sleep(8)
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(3)
    
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    rows = soup.find_all('ytmc-entry-row')
    
    # ë¡œë”© ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
    if not rows:
        time.sleep(5)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        rows = soup.find_all('ytmc-entry-row')
    
    data_list = []
    today = datetime.now().strftime("%Y-%m-%d")
    rank = 1
    
    # ì°¨íŠ¸ íƒ€ì… í”Œë˜ê·¸
    is_trending = "Trending" in chart_name
    is_daily_mv = "Daily_Top_MV" in chart_name
    is_weekly = "Weekly" in chart_name 
    is_shorts = "Shorts" in chart_name
    
    for row in rows:
        try:
            # 1. ì œëª©/ì•„í‹°ìŠ¤íŠ¸
            title = row.find('div', class_='title').get_text(strip=True)
            artist = ""
            artist_tag = row.find('span', class_='artistName')
            if not artist_tag: artist_tag = row.find('div', class_='subtitle')
            if artist_tag: artist = artist_tag.get_text(strip=True)
            
            # 2. Video ID ì¶”ì¶œ (ê°•ë ¥í•´ì§„ ë¡œì§)
            vid = ""
            
            # [Method 3] <a> íƒœê·¸ì˜ href ì†ì„±ì—ì„œ ì¶”ì¶œ (ê°€ì¥ ì •í™•í•¨, Shorts í•´ê²°ì±…)
            # ë³´í†µ href="/watch?v=ID" ë˜ëŠ” music.youtube.com/watch?v=ID í˜•íƒœì„
            anchor = row.find('a')
            if anchor and 'href' in anchor.attrs:
                href = anchor['href']
                # v= ë’¤ì— ì˜¤ëŠ” 11ìë¦¬ ID ì¶”ì¶œ
                match_href = re.search(r'v=([a-zA-Z0-9_-]{11})', href)
                if match_href:
                    vid = match_href.group(1)
            
            # hrefë¡œ ëª» ì°¾ì•˜ì„ ê²½ìš°(ê±°ì˜ ì—†ì§€ë§Œ), ê¸°ì¡´ img src ë°©ì‹ ë°±ì—… ì‹¤í–‰
            if not vid:
                img = row.find('img')
                if img and 'src' in img.attrs:
                    match_img = re.search(r'/vi(?:_webp)?/([a-zA-Z0-9_-]{11})', img['src'])
                    if match_img:
                        vid = match_img.group(1)
            
            final_views = 0
            
            # 3. ë·° ì¹´ìš´íŠ¸ ë° í›„ì²˜ë¦¬ ì „ëµ
            
            # [A] Trending: API (0ìœ¼ë¡œ ë‘ )
            if is_trending:
                pass 

            # [B] Shorts: ë”¥ë‹¤ì´ë¸Œ ì˜ˆì • (0ìœ¼ë¡œ ë‘ )
            elif is_shorts:
                pass

            # [C] Daily Top MV (ë¬¸ì œì˜ êµ¬ê°„ í•´ê²°)
            # ìŠ¤í¬ë¦°ìƒ· ë¶„ì„: tablet-non-displayed-metric í´ë˜ìŠ¤ê°€ 2ê°œ ìˆìŒ.
            # í•˜ë‚˜ëŠ” ìˆœìœ„ë³€ë™(ì‘ì€ìˆ˜), í•˜ë‚˜ëŠ” ë·°ì¹´ìš´íŠ¸(í°ìˆ˜/hidden).
            # ì „ëµ: í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ëª¨ë“  ë†ˆì„ ì°¾ì•„ì„œ ê°€ì¥ í° ê°’ì„ Viewë¡œ ê°„ì£¼í•œë‹¤.
            elif is_daily_mv:
                hidden_metrics = row.find_all('div', class_='tablet-non-displayed-metric')
                max_val = 0
                for m in hidden_metrics:
                    txt = m.get_text(strip=True)
                    val = parse_count_strict(txt)
                    if val > max_val:
                        max_val = val
                final_views = max_val

            # [D] Weekly: ë§¨ ì˜¤ë¥¸ìª½ metric
            elif is_weekly:
                metrics = row.find_all('div', class_='metric')
                if metrics:
                    final_views = parse_count_strict(metrics[-1].get_text(strip=True))

            data_list.append({
                "Date": today,
                "Chart": chart_name,
                "Rank": rank,
                "Title": title,
                "Artist": artist,
                "Video_ID": vid,
                "Views": final_views
            })
            rank += 1
        except: continue
        
    return data_list

# ================= ë©”ì¸ ì‹¤í–‰ =================
if __name__ == "__main__":
    driver = get_driver()
    final_data = []
    
    for name, url in TARGET_URLS.items():
        try:
            # 1. ê¸°ë³¸ ìˆ˜ì§‘
            chart_data = scrape_chart(driver, name, url)
            
            # 2. í›„ì²˜ë¦¬
            
            # [Trending] API ì‚¬ìš©
            if "Trending" in name:
                ids = [d["Video_ID"] for d in chart_data if d["Video_ID"]]
                if ids:
                    api_stats = get_views_from_api(ids)
                    for item in chart_data:
                        if item["Video_ID"] in api_stats:
                            item["Views"] = api_stats[item["Video_ID"]]
            
            # [Shorts] ë”¥ë‹¤ì´ë¸Œ (IDê°€ ì´ì œ í™•ì‹¤í•˜ë¯€ë¡œ ì˜ ì‘ë™í•¨)
            elif "Shorts" in name:
                print(f"  â†³ ğŸ•µï¸â€â™‚ï¸ Shorts Deep Dive ({len(chart_data)} items)...")
                for item in chart_data:
                    if item["Video_ID"]:
                        cnt = get_shorts_count_deep(driver, item["Video_ID"])
                        item["Views"] = cnt
            
            final_data.extend(chart_data)
            print(f"âœ… {name}: {len(chart_data)} rows done.")
            
        except Exception as e:
            print(f"Error on {name}: {e}")
            
    driver.quit()
    
    webhook = os.environ.get("APPS_SCRIPT_WEBHOOK")
    if final_data and webhook:
        print(f"Total {len(final_data)} rows. Sending...")
        try:
            requests.post(webhook, json=final_data)
            print("Success!")
        except Exception as e:
            print(f"Send Error: {e}")
    else:
        print("No data or webhook missing.")
